{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fbc47c2-b8b0-4c3a-beb5-f087f4972aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-18 11:51:25.577262: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-18 11:51:25.618222: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-18 11:51:26.503898: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "625d7239-25eb-4241-bb90-7b8d1caa5e7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m CAPTIONS_FILE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/Fliker8K/captions.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m OUTPUT_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/Fliker8K_processed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m IMG_SIZE \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\n\u001b[1;32m     13\u001b[0m TRAIN_RATIO \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.10/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/content'"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - CORRIG√âE\n",
    "# ============================================================================\n",
    "\n",
    "DATA_DIR = \"data/\"\n",
    "IMAGES_DIR = \"data/Images\"  # ‚ö†Ô∏è I majuscule\n",
    "CAPTIONS_FILE = \"data/captions.txt\"\n",
    "\n",
    "OUTPUT_DIR = \"split_data/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "TRAIN_RATIO = 0.8\n",
    "VAL_RATIO = 0.1\n",
    "TEST_RATIO = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6a4b49-a376-480f-857c-781b5cfe7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 1. CHARGEMENT DES CAPTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def load_captions(captions_file):\n",
    "    \"\"\"\n",
    "    Charge le fichier captions.txt et retourne un DataFrame\n",
    "    Format attendu: image,caption\n",
    "    \"\"\"\n",
    "    print(\"üìñ Chargement des captions...\")\n",
    "    df = pd.read_csv(captions_file)\n",
    "\n",
    "    # Nettoyage de base\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    print(f\"‚úÖ {len(df)} captions charg√©es pour {df['image'].nunique()} images\")\n",
    "    print(f\"Exemple:\\n{df.head()}\\n\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b4e6b-3491-40cc-994a-1b1547788557",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 2. SPLIT TRAIN/VAL/TEST\n",
    "# ============================================================================\n",
    "\n",
    "def split_dataset(df, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    Split le dataset au niveau des images (pas des captions)\n",
    "    Une image peut avoir plusieurs captions, donc on garde toutes les captions ensemble\n",
    "    \"\"\"\n",
    "    print(\"‚úÇÔ∏è  Split du dataset...\")\n",
    "\n",
    "    # Obtenir la liste unique des images\n",
    "    unique_images = df['image'].unique()\n",
    "    print(f\"Nombre d'images uniques: {len(unique_images)}\")\n",
    "\n",
    "    # Split train/temp\n",
    "    train_imgs, temp_imgs = train_test_split(\n",
    "        unique_images,\n",
    "        test_size=(val_ratio + test_ratio),\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Split val/test\n",
    "    val_imgs, test_imgs = train_test_split(\n",
    "        temp_imgs,\n",
    "        test_size=test_ratio/(val_ratio + test_ratio),\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Cr√©er les DataFrames\n",
    "    train_df = df[df['image'].isin(train_imgs)].reset_index(drop=True)\n",
    "    val_df = df[df['image'].isin(val_imgs)].reset_index(drop=True)\n",
    "    test_df = df[df['image'].isin(test_imgs)].reset_index(drop=True)\n",
    "\n",
    "    print(f\"‚úÖ Train: {len(train_imgs)} images, {len(train_df)} captions\")\n",
    "    print(f\"‚úÖ Val:   {len(val_imgs)} images, {len(val_df)} captions\")\n",
    "    print(f\"‚úÖ Test:  {len(test_imgs)} images, {len(test_df)} captions\\n\")\n",
    "\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb080198-68be-4838-8f15-e441b40ff32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3. PR√âTRAITEMENT DES IMAGES\n",
    "# ============================================================================\n",
    "\n",
    "def preprocess_image(img_path, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Charge et pr√©traite UNE image pour VGG16:\n",
    "    - Resize √† (224, 224)\n",
    "    - Convert to array\n",
    "    - Normalisation VGG16 (ImageNet)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Charger l'image\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Resize\n",
    "        img = img.resize(target_size, Image.LANCZOS)\n",
    "\n",
    "        # Convert to array\n",
    "        img_array = img_to_array(img)\n",
    "\n",
    "        # Normalisation VGG16 (soustraction moyenne ImageNet)\n",
    "        img_array = preprocess_input(img_array)\n",
    "\n",
    "        return img_array\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur avec {img_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec28739c-3326-427e-9722-bd6f94f91c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images_batch(df, images_dir, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Pr√©traite toutes les images d'un DataFrame\n",
    "    Retourne un dictionnaire {image_name: preprocessed_array}\n",
    "    \"\"\"\n",
    "    print(f\"üñºÔ∏è  Pr√©traitement de {df['image'].nunique()} images...\")\n",
    "\n",
    "    processed_images = {}\n",
    "    unique_images = df['image'].unique()\n",
    "\n",
    "    for img_name in tqdm(unique_images, desc=\"Processing images\"):\n",
    "        img_path = os.path.join(images_dir, img_name)\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"‚ö†Ô∏è  Image non trouv√©e: {img_name}\")\n",
    "            continue\n",
    "\n",
    "        img_array = preprocess_image(img_path, target_size)\n",
    "\n",
    "        if img_array is not None:\n",
    "            processed_images[img_name] = img_array\n",
    "\n",
    "    print(f\"‚úÖ {len(processed_images)} images pr√©trait√©es\\n\")\n",
    "\n",
    "    return processed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac955d6b-0b5b-4818-9c6f-bc9b5938a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 4. SAUVEGARDE\n",
    "# ============================================================================\n",
    "\n",
    "def save_split(split_name, df, images_dict, output_dir):\n",
    "    \"\"\"\n",
    "    Sauvegarde un split (train/val/test):\n",
    "    - DataFrame des captions\n",
    "    - Dictionnaire des images pr√©trait√©es\n",
    "    \"\"\"\n",
    "    print(f\"üíæ Sauvegarde du split {split_name}...\")\n",
    "\n",
    "    split_dir = os.path.join(output_dir, split_name)\n",
    "    os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "    # Sauvegarder les captions (CSV)\n",
    "    captions_path = os.path.join(split_dir, \"captions.csv\")\n",
    "    df.to_csv(captions_path, index=False)\n",
    "\n",
    "    # Sauvegarder les images (pickle pour rapidit√©)\n",
    "    images_path = os.path.join(split_dir, \"images_preprocessed.pkl\")\n",
    "    with open(images_path, 'wb') as f:\n",
    "        pickle.dump(images_dict, f)\n",
    "\n",
    "    print(f\"‚úÖ Sauvegard√© dans {split_dir}\")\n",
    "    print(f\"   - Captions: {len(df)} lignes\")\n",
    "    print(f\"   - Images: {len(images_dict)} fichiers\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea21ee-e7c6-4019-be4d-1647723379f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_splits(train_df, val_df, test_df,\n",
    "                    train_imgs, val_imgs, test_imgs,\n",
    "                    output_dir):\n",
    "    \"\"\"\n",
    "    Sauvegarde tous les splits\n",
    "    \"\"\"\n",
    "    save_split(\"train\", train_df, train_imgs, output_dir)\n",
    "    save_split(\"val\", val_df, val_imgs, output_dir)\n",
    "    save_split(\"test\", test_df, test_imgs, output_dir)\n",
    "\n",
    "    print(\"üéâ Tous les splits sauvegard√©s avec succ√®s!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f71b8a-165f-4f96-a64f-ff2212eb2f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 5. PIPELINE PRINCIPAL\n",
    "# ============================================================================\n",
    "\n",
    "def preprocess_flickr8k(data_dir, images_dir, captions_file, output_dir,\n",
    "                        train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Pipeline complet de pr√©traitement\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"üöÄ PR√âTRAITEMENT FLICKR8K POUR VGG16\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    # 1. Charger les captions\n",
    "    df = load_captions(captions_file)\n",
    "\n",
    "    # 2. Split train/val/test\n",
    "    train_df, val_df, test_df = split_dataset(\n",
    "        df, train_ratio, val_ratio, test_ratio\n",
    "    )\n",
    "\n",
    "    # 3. Pr√©traiter les images\n",
    "    print(\"üîÑ Pr√©traitement des images pour chaque split...\\n\")\n",
    "\n",
    "    train_imgs = preprocess_images_batch(train_df, images_dir)\n",
    "    val_imgs = preprocess_images_batch(val_df, images_dir)\n",
    "    test_imgs = preprocess_images_batch(test_df, images_dir)\n",
    "\n",
    "    # 4. Sauvegarder\n",
    "    save_all_splits(train_df, val_df, test_df,\n",
    "                   train_imgs, val_imgs, test_imgs,\n",
    "                   output_dir)\n",
    "\n",
    "    print(\"=\"*70)\n",
    "    print(\"‚ú® PR√âTRAITEMENT TERMIN√â\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    return {\n",
    "        'train': (train_df, train_imgs),\n",
    "        'val': (val_df, val_imgs),\n",
    "        'test': (test_df, test_imgs)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7a947f-1d89-44a5-849a-b76da7602182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 6. FONCTION DE CHARGEMENT (POUR PLUS TARD)\n",
    "# ============================================================================\n",
    "\n",
    "def load_preprocessed_split(split_name, output_dir):\n",
    "    \"\"\"\n",
    "    Charge un split pr√©trait√©\n",
    "    \"\"\"\n",
    "    split_dir = os.path.join(output_dir, split_name)\n",
    "\n",
    "    # Charger captions\n",
    "    captions_path = os.path.join(split_dir, \"captions.csv\")\n",
    "    df = pd.read_csv(captions_path)\n",
    "\n",
    "    # Charger images\n",
    "    images_path = os.path.join(split_dir, \"images_preprocessed.pkl\")\n",
    "    with open(images_path, 'rb') as f:\n",
    "        images_dict = pickle.load(f)\n",
    "\n",
    "    print(f\"‚úÖ Charg√© {split_name}: {len(df)} captions, {len(images_dict)} images\")\n",
    "\n",
    "    return df, images_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ad64e5-99b2-4078-a562-c7501fc5371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EX√âCUTION DU PR√âTRAITEMENT FLICKR8K\n",
    "# ============================================================================\n",
    "\n",
    "# Lancer le pr√©traitement\n",
    "data = preprocess_flickr8k(\n",
    "    data_dir=DATA_DIR,\n",
    "    images_dir=IMAGES_DIR,\n",
    "    captions_file=CAPTIONS_FILE,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    train_ratio=TRAIN_RATIO,\n",
    "    val_ratio=VAL_RATIO,\n",
    "    test_ratio=TEST_RATIO\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä R√âSUM√â FINAL\")\n",
    "print(\"=\"*70)\n",
    "print(f\"‚úÖ Train: {len(data['train'][0])} captions, {len(data['train'][1])} images\")\n",
    "print(f\"‚úÖ Val:   {len(data['val'][0])} captions, {len(data['val'][1])} images\")\n",
    "print(f\"‚úÖ Test:  {len(data['test'][0])} captions, {len(data['test'][1])} images\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# V√©rifier que tout est bien sauvegard√©\n",
    "print(\"\\nüîç V√©rification des fichiers sauvegard√©s:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_dir = os.path.join(OUTPUT_DIR, split)\n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    print(f\"  üìÅ {split_dir}\")\n",
    "    for file in os.listdir(split_dir):\n",
    "        file_path = os.path.join(split_dir, file)\n",
    "        size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "        print(f\"    ‚îú‚îÄ‚îÄ {file} ({size_mb:.2f} MB)\")\n",
    "\n",
    "print(\"\\n‚ú® Pr√©traitement termin√© ! Pr√™t pour l'√©tape suivante.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2996c78b-9e6e-47fb-aa7e-f3a52865a5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/content/drive/MyDrive/Fliker8K_processed\"\n",
    "\n",
    "# Charger images pr√©trait√©es, split_name train ou test ou val \n",
    "def load_images_preprocessed(split_name, output_dir):\n",
    "    split_dir = os.path.join(output_dir, split_name)\n",
    "    images_path = os.path.join(split_dir, \"images_preprocessed.pkl\")\n",
    "    with open(images_path, 'rb') as f:\n",
    "        images_dict = pickle.load(f)\n",
    "    return images_dict\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    images_dict = load_images_preprocessed(split, output_dir)\n",
    "    save_features(split, output_dir, images_dict, vgg_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ec3a71-c258-4695-836e-c24d704958b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2baca9-3a34-46f5-a950-3d667b424d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cab775-fbab-404b-b707-6547807d1605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
